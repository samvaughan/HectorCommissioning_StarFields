Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Conda environments: ignored
Job counts:
	count	jobs
	1	mask_targets_catalogue
	3
Select jobs to execute...

[Tue Jun 15 15:07:56 2021]
rule mask_targets_catalogue:
    input: results/StarCatalogues/Panstarrs_match_Gaia_270_m20_targets.csv, resources/IDs_for_tile_selection/270_m22_equally_spaced_IDs.txt
    output: results/StarCatalogues/equally_spaced_270_m22.csv
    jobid: 2

[Tue Jun 15 15:07:58 2021]
Finished job 2.
1 of 3 steps (33%) done
Complete log: /Users/samvaughan/Science/Hector/Targets/HectorInputCatalogues/Commissioning/StarFields/.snakemake/log/2021-06-15T150755.903512.snakemake.log
